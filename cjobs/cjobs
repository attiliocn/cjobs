#!/usr/bin/env python3

import configparser
import datetime
import os
import pathlib
import sys

CJOBS_DIR = sys.path[0]
sys.path.append(CJOBS_DIR)
from tools.arguments import create_argument_parser
from tools.config import config_cjobs_defaults
from tools.container_tools import (is_cached_containers_file_old,
                                   parse_containers_list,
                                   request_containers_using_rclone,
                                   show_cached_containers_file_contents)
from tools.scheduler_tools import get_scheduler_variables
from tools.util import get_hash_from_timestamp
from tools.write_job import write_job


parser = create_argument_parser()
args = parser.parse_args()

config_dir = os.path.join(os.environ['HOME'], '.config', 'cjobs')
config_file = os.path.join(config_dir, 'cjobsrc')

if args.subparser == 'config':
    config_cjobs_defaults(config_dir, config_file)
    exit()

# read config file
config = configparser.ConfigParser()
try:
    with open(config_file) as f:
        config.read_file(f)
except FileNotFoundError:
    print('Error: Configuration file not found.')
    exit()

try:
    SCHEDULER = config['SCHEDULER']['engine']
    SCRATCH_DIR = config['SCHEDULER']['scratch dir']
    PERSONAL_SCRATCH_DIR = config['SCHEDULER']['personal scratch dir']
    CONTAINERS_CLOUD_DIR = config['CONTAINERS']['cloud dir']
    CONTAINERS_LOCAL_DIR = config['CONTAINERS']['local dir']
    CONTAINER_MODE = config['CONTAINERS']['container mode']
    SINGULARITY_VERSION = config['CONTAINERS']['singularity version']
    SHARED_GID = config['FILE MANAGEMENT']['shared gid']
except KeyError:
    print("\nERROR: Your .cjobsrc file is outdated.\nPlease refer to the documentation to find the current version and update it accordingly.\n")
    exit()

# containers cached file
containers_avail_file = os.path.join(config_dir, 'containers.txt')
if args.subparser == 'listcontainers':
    if is_cached_containers_file_old(containers_avail_file):
        print("Updating the cached containers list")
        stdout, stderr = request_containers_using_rclone(CONTAINERS_CLOUD_DIR)
        if stderr:
            print(stderr)
            print("Could not fetch containers list from Google Drive.\nCheck your configuration file and try again")
            exit()
        else:
            containers = [i for i in stdout.split('\n')]
            containers.sort()
            with open(containers_avail_file, mode='w') as container_file:
                container_file.write("{: <15}{: <25}{: <}\n".format('Container ID', "Build Time", "File"))
                for container in containers:
                    container_data = container.replace('.sif','')
                    container_data = container_data.split('_')
                    container_file.write("{: <15}{: <25}{: <}\n".format(container_data[-1], container_data[-2], container))
            print("Update completed\n")
            show_cached_containers_file_contents(containers_avail_file)
            exit()
    else:
        print("Displaying containers from the cached file\n")
        show_cached_containers_file_contents(containers_avail_file)
        exit()

# check if container is valid
stdout, stderr = request_containers_using_rclone(CONTAINERS_CLOUD_DIR)
containers_list = [i for i in stdout.split('\n')]
containers_data = parse_containers_list(containers_list)
if args.container not in containers_data.keys():
    print(f'Invalid container. Container {args.container} not found!')
    print('Use cjobs listcontainers for a list of valid containers')
    exit()

# convert jobtime from hours to input format HH:MM:SS
duration = datetime.timedelta(hours=args.time)
totsec = duration.total_seconds()
h = totsec//3600
m = (totsec%3600) // 60
sec =(totsec%3600)%60 #just for reference
args.time = f"{int(h):02d}:{int(m):02d}:{int(sec):02d}"

# scheduler variables
scheduler_variables = get_scheduler_variables(SCHEDULER)

if args.array and len(args.job) > 1:
    # create the queue config file
    with open('queue.conf', mode='w') as f:
        for i, job in enumerate(args.job):
            f.write(f'{i+1},{job}\n')

    job_scratch_dir = f"\"{PERSONAL_SCRATCH_DIR}/\"{scheduler_variables['job_id']}\"/\"{scheduler_variables['array_task_id']}\"\""
    job_scratch_dir_in_script = 'job_scratch_dir'
    
    job_input = f'$(awk -F "," -v ArrayTaskID=\"{scheduler_variables["array_task_id"]}\" ' + r"'$1==ArrayTaskID {print $2}' " + f'"${job_scratch_dir_in_script}"/queue.conf)'
    job_input_in_script = 'job_input'

    job_tag = f"array_{get_hash_from_timestamp()[:6]}"
    job_name = fr"$(echo ${job_input_in_script} | rev | cut -f 2- -d '.' | rev)"
    job_name_in_script = 'job_name'

    job_local_dir =f'{os.getcwd()}'
    job_local_dir_in_script = 'job_local_dir'

    write_job(
            args,
            scheduler=SCHEDULER, 
            containers_cloud_dir=CONTAINERS_CLOUD_DIR, 
            containers_local_dir=CONTAINERS_LOCAL_DIR,
            container=containers_data[args.container]['file'],
            shared_gid = SHARED_GID,
            singularity_version=SINGULARITY_VERSION,
            scratch_dir=SCRATCH_DIR,
            job_input=job_input,
            job_input_in_script=job_input_in_script,
            job_tag=job_tag,
            job_name=job_name,
            job_name_in_script=job_name_in_script,
            job_local_dir=job_local_dir,
            job_local_dir_in_script=job_local_dir_in_script,
            job_scratch_dir=job_scratch_dir,
            job_scratch_dir_in_script=job_scratch_dir_in_script
        )
else:
    for job in args.job:     
        job_input = job
        job_input_in_script = 'job_input'

        job_tag = pathlib.Path(job_input).stem
        job_name = job_tag
        job_name_in_script = 'job_name'
        
        job_local_dir =f'{os.getcwd()}'
        job_local_dir_in_script = 'job_local_dir'

        job_scratch_dir = f"\"{PERSONAL_SCRATCH_DIR}/\"{scheduler_variables['job_id']}\"\""
        job_scratch_dir_in_script = 'job_scratch_dir'

        write_job(
            args,
            scheduler=SCHEDULER, 
            containers_cloud_dir=CONTAINERS_CLOUD_DIR, 
            containers_local_dir=CONTAINERS_LOCAL_DIR,
            container=containers_data[args.container]['file'],
            shared_gid = SHARED_GID,
            singularity_version=SINGULARITY_VERSION,
            scratch_dir=SCRATCH_DIR,
            job_input=job_input,
            job_input_in_script=job_input_in_script,
            job_tag=job_tag,
            job_name=job_name,
            job_name_in_script=job_name_in_script,
            job_local_dir=job_local_dir,
            job_local_dir_in_script=job_local_dir_in_script,
            job_scratch_dir=job_scratch_dir,
            job_scratch_dir_in_script=job_scratch_dir_in_script
        )

    
